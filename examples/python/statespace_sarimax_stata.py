# coding: utf-8

# DO NOT EDIT
# Autogenerated from the notebook statespace_sarimax_stata.ipynb.
# Edit the notebook and then sync the output with this file.
#
# flake8: noqa
# DO NOT EDIT

# # SARIMAX：简介

# 这个笔记复制了 Stata 的 ARIMA 时间序列估计和后估计文档中的示例。
#
# 首先，我们复制四个估计示例 http://www.stata.com/manuals13/tsarima.pdf:
#
# 1.美国批发价格指数（WPI）数据集上的 ARIMA(1,1,1) 模型。
# 2.示例1的变体，在 ARIMA(1,1,1)）规范中添加了 MA(4)项，以实现加性的季节性影响。
# 3.每月航空公司数据的 ARIMA(2,1,0) x (1,1,0,12) 模型。 这个例子允许一个乘法季节性影响。
# 4.具有外生回归变量的 ARMA(1,1) 模型； 将消费描述为自回归过程，在此过程中，货币供应量是被假定为一个解释变量。
# 
#
# 其次，我们从 http://www.stata.com/manuals13/tsarimapostestimation.pdf 复制来演示后估计性能。 以示例 4 中的模型作为演示：
#
# 1.提前 one-step 样本内预测
# 2.提前 n-step 样本外预测
# 3.提前 n-step 样本内动态预测

import numpy as np
import pandas as pd
from scipy.stats import norm
import statsmodels.api as sm
import matplotlib.pyplot as plt
from datetime import datetime
import requests
from io import BytesIO

# ### ARIMA 示例 1: Arima
#
# 
# 从示例 2 的图表中可以看出，批发价格指数 (WPI) 随时间增长（即不平稳）。 因此，ARMA 模型不是一个很好的规范。 
# 在第一个示例中，我们认为一个模型，其中，在该模型中原始时间序列被假定为阶次积分
#
# 1 因此假设差异是固定的，并拟合具有一个自回归滞后和一个移动平均滞后并有一个截距项的模型。
#
# 然后假定的数据处理:
#
# $$
# \Delta y_t = c + \phi_1 \Delta y_{t-1} + \theta_1 \epsilon_{t-1} +
# \epsilon_{t}
# $$
#
# 其中 $c$ 是 ARMA 模型的截距，$\Delta$ 是一阶差分运算符，我们假定 $\epsilon_{t} \sim N(0, \sigma^2)$。
# 可以将其重写为强调滞后多项式（在下面的示例2中将很有用）
#
# $$
# (1 - \phi_1 L ) \Delta y_t = c + (1 + \theta_1 L) \epsilon_{t}
# $$
#
# 其中 $L$ 是滞后运算符。
#
# 请注意，存在一个差异 —— Stata 输出的模型与下方输出的 Stata估计模型：
#
# $$
# (\Delta y_t - \beta_0) = \phi_1 ( \Delta y_{t-1} - \beta_0) + \theta_1
# \epsilon_{t-1} + \epsilon_{t}
# $$
#
# 其中 $\beta_0$ 是程序 $y_t$ 的平均值。该模型等效于 statsmodels SARIMAX 类中估计的模型，但是解释不同。
# 要查看等效项，请注意：
#
# $$
# (\Delta y_t - \beta_0) = \phi_1 ( \Delta y_{t-1} - \beta_0) + \theta_1
# \epsilon_{t-1} + \epsilon_{t} \\
# \Delta y_t = (1 - \phi_1) \beta_0 + \phi_1 \Delta y_{t-1} + \theta_1
# \epsilon_{t-1} + \epsilon_{t}
# $$
#
# 因此 $c = (1 - \phi_1) \beta_0$.

# 数据集
wpi1 = requests.get('https://www.stata-press.com/data/r12/wpi1.dta').content
data = pd.read_stata(BytesIO(wpi1))
data.index = data.t

# 拟合模型
mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c', order=(1, 1, 1))
res = mod.fit(disp=False)
print(res.summary())

# 因此，对于上述过程极大似然估计意味着，我们有:
#
# $$
# \Delta y_t = 0.1050 + 0.8740 \Delta y_{t-1} - 0.4206 \epsilon_{t-1} +
# \epsilon_{t}
# $$
#
# 其中 $\epsilon_{t} \sim N(0, 0.5226)$. Finally, 最后，回想一下 $c = (1 - \phi_1) \beta_0$, 
# 在这里 $c = 0.1050$ 且 $\phi_1 = 0.8740$ 。 为了与Stata的输出进行比较，我们可以计算出平均值：
#
# $$\beta_0 = \frac{c}{1 - \phi_1} = \frac{0.1050}{1 - 0.8740} = 0.83$$
#
# **注意**：这些值与 Stata 文档中的值略有不同，因为 statsmodels 的优化器在此处慧生成一个更高似然的参数。尽管如此，它们非常接近。



# ### ARIMA 示例 2: 附带季节性影响的 Arima 模型 
#
# $$
# \Delta y_t = c + \phi_1 \Delta y_{t-1} + \theta_1 \epsilon_{t-1} +
# \theta_4 \epsilon_{t-4} + \epsilon_{t}
# $$
#
# 该模型的新部分是允许有年度季节性影响（即使周期性为4，因为数据集是季度性的，所以它也是年度的）。 第二个区别是该模型使用数据日志而不是水平。
# 
#
# 在估计数据集之前，图形显示：
#
# 1.时间序列（以日志为单位）
# 2.时间序列的第一个差异（以日志为单位）
# 3.自相关函数
# 4.偏自相关函数
#
# 从前两个图表中，我们注意到原始时间序列似乎不是平稳的，而一阶差异却是平稳的。要么根据数据的一阶差异估计一个 ARMA 模型，
# 要么估计一个带有一阶积分的 ARIMA 模型（回想一下，我们采用的是后一种方法）。最后两个图支持使用 ARMA(1,1,1) 模型。


# 数据集
data = pd.read_stata(BytesIO(wpi1))
data.index = data.t
data['ln_wpi'] = np.log(data['wpi'])
data['D.ln_wpi'] = data['ln_wpi'].diff()

# 图形数据
fig, axes = plt.subplots(1, 2, figsize=(15, 4))

# 水平
axes[0].plot(data.index._mpl_repr(), data['wpi'], '-')
axes[0].set(title='US Wholesale Price Index')

# 日志差异
axes[1].plot(data.index._mpl_repr(), data['D.ln_wpi'], '-')
axes[1].hlines(0, data.index[0], data.index[-1], 'r')
axes[1].set(title='US Wholesale Price Index - difference of logs')

# 图形数据
fig, axes = plt.subplots(1, 2, figsize=(15, 4))

fig = sm.graphics.tsa.plot_acf(data.iloc[1:]['D.ln_wpi'], lags=40, ax=axes[0])
fig = sm.graphics.tsa.plot_pacf(data.iloc[1:]['D.ln_wpi'], lags=40, ax=axes[1])

# 为了了解如何在 statsmodels 中指定此模型，首先回想起示例 1，我们使用以下代码来指定 ARIMA(1,1,1) 模型：
#
# ```python
# mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c', order=(1,1,1))
# ```
#
# “ order”参数是元组的形式“（AR 规范，整合阶，MA 规范）”。 整合阶必须是整数（例如，在这里我们假设一阶整合，
# 因此将其指定为1。在基础数据已经固定的纯ARMA模型中，它将为0）。
#
#
# 对于 AR 规范和 MA 规范组件，有两种可能性。首先是指定相应滞后多项式的 **maximum degree** ，在这种情况下，该组件是整数。
# 例如，如果我们想指定一个 ARIMA(1,1,4) ，我们将使用：
#
# ```python
# mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c', order=(1,1,4))
# ```
#
# 相应的数据处理将是:
#
# $$
# y_t = c + \phi_1 y_{t-1} + \theta_1 \epsilon_{t-1} + \theta_2
# \epsilon_{t-2} + \theta_3 \epsilon_{t-3} + \theta_4 \epsilon_{t-4} +
# \epsilon_{t}
# $$
#
# 或者
#
# $$
# (1 - \phi_1 L)\Delta y_t = c + (1 + \theta_1 L + \theta_2 L^2 + \theta_3
# L^3 + \theta_4 L^4) \epsilon_{t}
# $$
#
# 当指定参数作为滞后多项式的最高阶次给出时，则意味着提高到所有多项式包含阶次。 请注意，这不是我们要使用的模型，
# 因为它包含 $\epsilon_{t-2}$ 和 $\epsilon_{t-3}$ 项，在这里我们不希望使用。
#
# 我们想要的是一个多项式，带有第 1 和第 4 阶次项，而没有第2 和第 3 阶次项。为此，我们需要为规范参数提供一个元组，
# 其中元组描述 **the lag polynomial itself**。 特别是，在这里我们要使用：
# 
#
# ```python
# ar = 1          # this is the maximum degree specification
# ma = (1,0,0,1)  # this is the lag polynomial specification
# mod = sm.tsa.statespace.SARIMAX(data['wpi'], trend='c',
# order=(ar,1,ma)))
# ```
#
# 这给出以下程式来做数据处理:
#
# $$
# \Delta y_t = c + \phi_1 \Delta y_{t-1} + \theta_1 \epsilon_{t-1} +
# \theta_4 \epsilon_{t-4} + \epsilon_{t} \\
# (1 - \phi_1 L)\Delta y_t = c + (1 + \theta_1 L + \theta_4 L^4)
# \epsilon_{t}
# $$
#
# 这是我们想要的.

# 拟合模型
mod = sm.tsa.statespace.SARIMAX(data['ln_wpi'], trend='c', order=(1, 1, 1))
res = mod.fit(disp=False)
print(res.summary())

# ### ARIMA 示例 3: Airline Model
#
# 在前面的示例中，我们以“加法”方式包括了季节性影响，这意味着我们添加一项允许进程依赖第 4 MA 滞后。
# 取而代之的是，我们希望以“乘法”方式对季节效应进行建模。我们通常将模型写成 ARIMA $(p,d,q)\times (P,D,Q)_s$，
# 其中小写字母表示非季节性成分的规范，大写字母表示季节性成分的规范； $s$ 是季节的周期性（例如，季度数据通常为4，月度数据通常为12）。
# 数据处理可以一般写为
#
# $$
# \phi_p (L) \tilde \phi_P (L^s) \Delta^d \Delta_s^D y_t = A(t) + \theta_q
# (L) \tilde \theta_Q (L^s) \epsilon_t
# $$
#
# 其中:
#
# - $\phi_p (L)$ 是非季节性自回归滞后多项式
# - $\tilde \phi_P (L^s)$ 是季节性自回归滞后多项式
# - $\Delta^d \Delta_s^D y_t$ 是时间序列, 相差 $d$ 次,而季节性相差 $D$ 次.
# - $A(t)$ 是趋势性多项式 (包含截距)
# - $\theta_q (L)$ 是非季节性移动平均滞后多项式
# - $\tilde \theta_Q (L^s)$ 是季节性移动平均滞后多项式
#
# 有时我们可以改写为:
#
# $$
# \phi_p (L) \tilde \phi_P (L^s) y_t^* = A(t) + \theta_q (L) \tilde
# \theta_Q (L^s) \epsilon_t
# $$
#
# 其中 $y_t^* = \Delta^d \Delta_s^D y_t$. 这强调了在简单的情况下，我们采用差异（这里是非季节性和季节性）来使数据稳定之后，
# 所得到的模型是一个 ARMA 模型。
#
# 例如，考虑带有截距的航空公司模型 ARIMA $(2,1,0) \times(1,1,0)_{12}$。数据处理可以按上面的程式写成：
#
# $$
# (1 - \phi_1 L - \phi_2 L^2) (1 - \tilde \phi_1 L^{12}) \Delta
# \Delta_{12} y_t = c + \epsilon_t
# $$
#
# 在这里有:
#
# - $\phi_p (L) = (1 - \phi_1 L - \phi_2 L^2)$
# - $\tilde \phi_P (L^s) = (1 - \phi_1 L^12)$
# - $d = 1, D = 1, s=12$ 表示 $y_t^*$ 是从第 1 阶差异到第 12 阶差异派生的
# - $A(t) = c$ 是 *恒定* 趋势性多项式（即一个截距）
# - $\theta_q (L) = \tilde \theta_Q (L^s) = 1$ (即没有移动平均效应）
#
# It may still be confusing to see the two lag polynomials in front of the
# time-series variable, but notice that we can multiply the lag polynomials
# together to get the following model:
#
# $$
# (1 - \phi_1 L - \phi_2 L^2 - \tilde \phi_1 L^{12} + \phi_1 \tilde \phi_1
# L^{13} + \phi_2 \tilde \phi_1 L^{14} ) y_t^* = c + \epsilon_t
# $$
#
# which can be rewritten as:
#
# $$
# y_t^* = c + \phi_1 y_{t-1}^* + \phi_2 y_{t-2}^* + \tilde \phi_1
# y_{t-12}^* - \phi_1 \tilde \phi_1 y_{t-13}^* - \phi_2 \tilde \phi_1
# y_{t-14}^* + \epsilon_t
# $$
#
# This is similar to the additively seasonal model from example 2, but the
# coefficients in front of the autoregressive lags are actually combinations
# of the underlying seasonal and non-seasonal parameters.
#
# Specifying the model in statsmodels is done simply by adding the
# `seasonal_order` argument, which accepts a tuple of the form `(Seasonal AR
# specification, Seasonal Integration order, Seasonal MA, Seasonal
# periodicity)`. The seasonal AR and MA specifications, as before, can be
# expressed as a maximum polynomial degree or as the lag polynomial itself.
# Seasonal periodicity is an integer.
#
# For the airline model ARIMA $(2,1,0) \times (1,1,0)_{12}$ with an
# intercept, the command is:
#
# ```python
# mod = sm.tsa.statespace.SARIMAX(data['lnair'], order=(2,1,0),
# seasonal_order=(1,1,0,12))
# ```

# Dataset
air2 = requests.get('https://www.stata-press.com/data/r12/air2.dta').content
data = pd.read_stata(BytesIO(air2))
data.index = pd.date_range(
    start=datetime(data.time[0], 1, 1), periods=len(data), freq='MS')
data['lnair'] = np.log(data['air'])

# Fit the model
mod = sm.tsa.statespace.SARIMAX(
    data['lnair'],
    order=(2, 1, 0),
    seasonal_order=(1, 1, 0, 12),
    simple_differencing=True)
res = mod.fit(disp=False)
print(res.summary())

# Notice that here we used an additional argument
# `simple_differencing=True`. This controls how the order of integration is
# handled in ARIMA models. If `simple_differencing=True`, then the time
# series provided as `endog` is literally differenced and an ARMA model is
# fit to the resulting new time series. This implies that a number of
# initial periods are lost to the differencing process, however it may be
# necessary either to compare results to other packages (e.g. Stata's
# `arima` always uses  simple differencing) or if the seasonal periodicity
# is large.
#
# The default is `simple_differencing=False`, in which case the
# integration component is implemented as part of the state space
# formulation, and all of the original data can be used in estimation.

# ### ARIMA Example 4: ARMAX (Friedman)
#
# This model demonstrates the use of explanatory variables (the X part of
# ARMAX). When exogenous regressors are included, the SARIMAX module uses
# the concept of "regression with SARIMA errors" (see
# http://robjhyndman.com/hyndsight/arimax/ for details of regression with
# ARIMA errors versus alternative specifications), so that the model is
# specified as:
#
# $$
# y_t = \beta_t x_t + u_t \\
#         \phi_p (L) \tilde \phi_P (L^s) \Delta^d \Delta_s^D u_t = A(t) +
#             \theta_q (L) \tilde \theta_Q (L^s) \epsilon_t
# $$
#
# Notice that the first equation is just a linear regression, and the
# second equation just describes the process followed by the error component
# as SARIMA (as was described in example 3). One reason for this
# specification is that the estimated parameters have their natural
# interpretations.
#
# This specification nests many simpler specifications. For example,
# regression with AR(2) errors is:
#
# $$
# y_t = \beta_t x_t + u_t \\
# (1 - \phi_1 L - \phi_2 L^2) u_t = A(t) + \epsilon_t
# $$
#
# The model considered in this example is regression with ARMA(1,1)
# errors. The process is then written:
#
# $$
# \text{consump}_t = \beta_0 + \beta_1 \text{m2}_t + u_t \\
# (1 - \phi_1 L) u_t = (1 - \theta_1 L) \epsilon_t
# $$
#
# Notice that $\beta_0$ is, as described in example 1 above, *not* the
# same thing as an intercept specified by `trend='c'`. Whereas in the
# examples above we estimated the intercept of the model via the trend
# polynomial, here, we demonstrate how to estimate $\beta_0$ itself by
# adding a constant to the exogenous dataset. In the output, the $beta_0$ is
# called `const`, whereas above the intercept $c$ was called `intercept` in
# the output.

# Dataset
friedman2 = requests.get(
    'https://www.stata-press.com/data/r12/friedman2.dta').content
data = pd.read_stata(BytesIO(friedman2))
data.index = data.time

# Variables
endog = data.loc['1959':'1981', 'consump']
exog = sm.add_constant(data.loc['1959':'1981', 'm2'])

# Fit the model
mod = sm.tsa.statespace.SARIMAX(endog, exog, order=(1, 0, 1))
res = mod.fit(disp=False)
print(res.summary())

# ### ARIMA Postestimation: Example 1 - Dynamic Forecasting
#
# Here we describe some of the post-estimation capabilities of
# statsmodels' SARIMAX.
#
# First, using the model from example, we estimate the parameters using
# data that *excludes the last few observations* (this is a little
# artificial as an example, but it allows considering performance of out-of-
# sample forecasting and facilitates comparison to Stata's documentation).

# Dataset
raw = pd.read_stata(BytesIO(friedman2))
raw.index = raw.time
data = raw.loc[:'1981']

# Variables
endog = data.loc['1959':, 'consump']
exog = sm.add_constant(data.loc['1959':, 'm2'])
nobs = endog.shape[0]

# Fit the model
mod = sm.tsa.statespace.SARIMAX(
    endog.loc[:'1978-01-01'], exog=exog.loc[:'1978-01-01'], order=(1, 0, 1))
fit_res = mod.fit(disp=False)
print(fit_res.summary())

# Next, we want to get results for the full dataset but using the
# estimated parameters (on a subset of the data).

mod = sm.tsa.statespace.SARIMAX(endog, exog=exog, order=(1, 0, 1))
res = mod.filter(fit_res.params)

# The `predict` command is first applied here to get in-sample
# predictions. We use the `full_results=True` argument to allow us to
# calculate confidence intervals (the default output of `predict` is just
# the predicted values).
#
# With no other arguments, `predict` returns the one-step-ahead in-sample
# predictions for the entire sample.

# In-sample one-step-ahead predictions
predict = res.get_prediction()
predict_ci = predict.conf_int()

# We can also get *dynamic predictions*. One-step-ahead prediction uses
# the true values of the endogenous values at each step to predict the next
# in-sample value. Dynamic predictions use one-step-ahead prediction up to
# some point in the dataset (specified by the `dynamic` argument); after
# that, the previous *predicted* endogenous values are used in place of the
# true endogenous values for each new predicted element.
#
# The `dynamic` argument is specified to be an *offset* relative to the
# `start` argument. If `start` is not specified, it is assumed to be `0`.
#
# Here we perform dynamic prediction starting in the first quarter of
# 1978.

# Dynamic predictions
predict_dy = res.get_prediction(dynamic='1978-01-01')
predict_dy_ci = predict_dy.conf_int()

# We can graph the one-step-ahead and dynamic predictions (and the
# corresponding confidence intervals) to see their relative performance.
# Notice that up to the point where dynamic prediction begins (1978:Q1), the
# two are the same.

# Graph
fig, ax = plt.subplots(figsize=(9, 4))
npre = 4
ax.set(
    title='Personal consumption', xlabel='Date', ylabel='Billions of dollars')

# Plot data points
data.loc['1977-07-01':, 'consump'].plot(ax=ax, style='o', label='Observed')

# Plot predictions
predict.predicted_mean.loc['1977-07-01':].plot(
    ax=ax, style='r--', label='One-step-ahead forecast')
ci = predict_ci.loc['1977-07-01':]
ax.fill_between(ci.index, ci.iloc[:, 0], ci.iloc[:, 1], color='r', alpha=0.1)
predict_dy.predicted_mean.loc['1977-07-01':].plot(
    ax=ax, style='g', label='Dynamic forecast (1978)')
ci = predict_dy_ci.loc['1977-07-01':]
ax.fill_between(ci.index, ci.iloc[:, 0], ci.iloc[:, 1], color='g', alpha=0.1)

legend = ax.legend(loc='lower right')

# Finally, graph the prediction *error*. It is obvious that, as one would
# suspect, one-step-ahead prediction is considerably better.

# Prediction error

# Graph
fig, ax = plt.subplots(figsize=(9, 4))
npre = 4
ax.set(title='Forecast error', xlabel='Date', ylabel='Forecast - Actual')

# In-sample one-step-ahead predictions and 95% confidence intervals
predict_error = predict.predicted_mean - endog
predict_error.loc['1977-10-01':].plot(ax=ax, label='One-step-ahead forecast')
ci = predict_ci.loc['1977-10-01':].copy()
ci.iloc[:, 0] -= endog.loc['1977-10-01':]
ci.iloc[:, 1] -= endog.loc['1977-10-01':]
ax.fill_between(ci.index, ci.iloc[:, 0], ci.iloc[:, 1], alpha=0.1)

# Dynamic predictions and 95% confidence intervals
predict_dy_error = predict_dy.predicted_mean - endog
predict_dy_error.loc['1977-10-01':].plot(
    ax=ax, style='r', label='Dynamic forecast (1978)')
ci = predict_dy_ci.loc['1977-10-01':].copy()
ci.iloc[:, 0] -= endog.loc['1977-10-01':]
ci.iloc[:, 1] -= endog.loc['1977-10-01':]
ax.fill_between(ci.index, ci.iloc[:, 0], ci.iloc[:, 1], color='r', alpha=0.1)

legend = ax.legend(loc='lower left')
legend.get_frame().set_facecolor('w')
